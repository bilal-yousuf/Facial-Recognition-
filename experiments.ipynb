{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### This file runs the Face Recognition (section 4) section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 out of 30\n",
      "Current best  HOG accuracy is 0.4142857142857143 with vocab_size=10 and cell_size=(4, 4) and patch_size=15\n",
      "1 4\n",
      "1 2\n",
      "Current best  LBP accuracy is 0.32857142857142857 with vocab_size=10 and radius=7 and patch_size=15\n",
      "Iteration 2 out of 30\n",
      "Current best  HOG accuracy is 0.4142857142857143 with vocab_size=10 and cell_size=(4, 4) and patch_size=15\n",
      "Current best  LBP accuracy is 0.32857142857142857 with vocab_size=10 and radius=7 and patch_size=15\n",
      "Iteration 3 out of 30\n",
      "Current best  HOG accuracy is 0.4142857142857143 with vocab_size=10 and cell_size=(4, 4) and patch_size=15\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "class HarrisFeature():\n",
    "    def __init__(self, x, y):\n",
    "        self.pt = (x, y)\n",
    "\n",
    "train_images = {}\n",
    "test_images = {}\n",
    "\n",
    "#assigns all training and test images to dictionary\n",
    "for i in range(0, 75):\n",
    "    file = \"./pictures/train/train\" + str(i) + \".jpg\"\n",
    "    train_images[\"train\" + str(i) + \".jpg\"] = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB)   \n",
    "for j in range(0,70):\n",
    "    file = \"./pictures/test/test\" + str(j) + \".jpg\"\n",
    "    test_images[\"test\" + str(j) + \".jpg\"] = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# grab the original images\n",
    "def clean_filename(path):\n",
    "    strings = path.split('/')\n",
    "    return strings[-1]\n",
    "\n",
    "def show_bounding_box(train_images, keys, face_coords, method='sift'):\n",
    "    keypoints = []\n",
    "    for key in keys:\n",
    "        x, y, w, h = face_coords[key]\n",
    "        img = train_images[key]\n",
    "        cpy = deepcopy(train_images[key])\n",
    "        cv2.rectangle(cpy, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        if method == 'sift':\n",
    "            # create a mask image filled with zeros, the size of original image\n",
    "            mask = np.zeros(cpy.shape[:2], dtype=np.uint8)\n",
    "            sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "            # draw your selected ROI on the mask image\n",
    "            cv2.rectangle(mask, (x, y), (x+w, y+h), (255), thickness = -1)\n",
    "\n",
    "            # provide mask to the detect method\n",
    "            kp, descriptorsTrain = sift.detectAndCompute(cpy,mask)\n",
    "            keypoints.append(kp)\n",
    "            img=cv2.drawKeypoints(img,kp,cpy)\n",
    "        elif method == 'harris':\n",
    "            box = extract_box_from_image(train_images[key], (x, y, w, h))\n",
    "            gray_box = cv2.cvtColor(box, cv2.COLOR_RGB2GRAY)\n",
    "            block_size = 4\n",
    "            k_size = 3\n",
    "            k = 0.04\n",
    "            corners = cv2.cornerHarris(gray_box, block_size, k_size, k)\n",
    "            threshold = 0.5 * corners.max()\n",
    "            kp_coords = np.where(corners >= threshold)\n",
    "            y_coords = kp_coords[0]\n",
    "            x_coords = kp_coords[1]\n",
    "            y_coords += y\n",
    "            x_coords += x\n",
    "            kp = []\n",
    "            for x, y in zip(x_coords, y_coords):\n",
    "                kp.append(HarrisFeature(x, y))\n",
    "            keypoints.append(kp)\n",
    "    return keypoints\n",
    "            \n",
    "\n",
    "def bound_faces(face_coords, images, method='sift'):\n",
    "    keypoints = {}\n",
    "    for key in images:\n",
    "        # Detect faces\n",
    "        if key in face_coords.keys():\n",
    "            keypoints[key] = show_bounding_box(images, [key], face_coords, method)[0]\n",
    "        else:\n",
    "            faces = face_cascade.detectMultiScale(images[key], 1.05, 5,flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "            if len(faces) == 0:\n",
    "                error_faces.append(key)\n",
    "                continue\n",
    "            for (x, y, w, h) in faces:\n",
    "                face_coords[key] = (x, y, w, h)\n",
    "                img = images[key]\n",
    "                cpy = deepcopy(images[key])\n",
    "\n",
    "                cv2.rectangle(cpy, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "                if method == 'sift':\n",
    "                    # create a mask image filled with zeros, the size of original image\n",
    "                    mask = np.zeros(cpy.shape[:2], dtype=np.uint8)\n",
    "                    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "                    # draw your selected ROI on the mask image\n",
    "                    cv2.rectangle(mask, (x, y), (x+w, y+h), (255), thickness = -1)\n",
    "\n",
    "                    # provide mask to the detect method\n",
    "                    kp, descriptorsTrain = sift.detectAndCompute(cpy,mask)\n",
    "                    img=cv2.drawKeypoints(img,kp,cpy)\n",
    "                elif method == 'harris':\n",
    "                    box = extract_box_from_image(images[key], (x, y, w, h))\n",
    "                    gray_box = cv2.cvtColor(box, cv2.COLOR_RGB2GRAY)\n",
    "                    block_size = 4\n",
    "                    k_size = 3\n",
    "                    k = 0.04\n",
    "                    corners = cv2.cornerHarris(gray_box, block_size, k_size, k)\n",
    "                    threshold = 0.5 * corners.max()\n",
    "                    kp_coords = np.where(corners >= threshold)\n",
    "                    y_coords = kp_coords[0]\n",
    "                    x_coords = kp_coords[1]\n",
    "                    y_coords += y\n",
    "                    x_coords += x\n",
    "                    kp = []\n",
    "                    for x, y in zip(x_coords, y_coords):\n",
    "                        kp.append(HarrisFeature(x, y))\n",
    "                keypoints[key] = kp\n",
    "                \n",
    "    return keypoints\n",
    "\n",
    "def extract_box_from_image(image, box_dims):\n",
    "    x, y, w, h = box_dims\n",
    "    return image[y : y + h, x : x + w]\n",
    "\n",
    "def create_patch(dim, image, key_points):\n",
    "    upper_bound = int(math.ceil(dim/2))\n",
    "    lower_bound = int(math.floor(dim/2))\n",
    "    patches = []\n",
    "    for kp in key_points:\n",
    "        x = int(kp.pt[0])\n",
    "        y = int(kp.pt[1])\n",
    "        \n",
    "        if x + upper_bound > image.shape[1] or x - lower_bound < 0:\n",
    "            print(\"error: {} x {} patch centered at this keypoint not in bounds of image\".format(dim, dim))\n",
    "            continue\n",
    "        \n",
    "        if y + upper_bound > image.shape[0] or y - lower_bound < 0:\n",
    "            print(\"error: {} x {} patch centered at this keypoint not in bounds of image\".format(dim, dim))\n",
    "            continue\n",
    "        \n",
    "        patch = image[y - lower_bound : y + upper_bound, x - lower_bound : x + upper_bound]\n",
    "        patches.append(patch)\n",
    "        \n",
    "    return patches\n",
    "\n",
    "def extract_hogs(patches, cell_size):\n",
    "    hogs = []\n",
    "    for p in patches:\n",
    "        hog_ft = hog(p, orientations=9, cells_per_block=(2,2), pixels_per_cell=cell_size, multichannel=True, feature_vector=True)\n",
    "        hogs.append(hog_ft)\n",
    "    return hogs\n",
    "def extract_lbps(patches, radius):\n",
    "    lbps = []\n",
    "    for p in patches:\n",
    "        gray_p = cv2.cvtColor(p, cv2.COLOR_RGB2GRAY)\n",
    "        lbp_ft = local_binary_pattern(gray_p, P=radius*8, R=radius)\n",
    "        lbps.append(lbp_ft.flatten())\n",
    "    return lbps\n",
    "\n",
    "def get_data_and_labels(imgs, kps, c_size=None, patch_size=None, descriptor='hog', radius=None):\n",
    "    if descriptor == 'hog':\n",
    "        if c_size is None or patch_size is None:\n",
    "            print(\"c_size and patch_size must be specified for HOG\")\n",
    "            exit(1)\n",
    "        all_train = []\n",
    "        image_to_hogs = {}\n",
    "        for key in imgs:\n",
    "\n",
    "            if key in error_faces:\n",
    "                continue\n",
    "\n",
    "            img_patches = create_patch(patch_size, imgs[key], kps[key])\n",
    "            t_hog = extract_hogs(img_patches, c_size)\n",
    "            image_to_hogs[key] = t_hog\n",
    "            all_train.extend(t_hog)\n",
    "\n",
    "        return all_train, image_to_hogs\n",
    "    elif descriptor == 'lbp':\n",
    "        if radius is None:\n",
    "            print(\"Please specify a radius when requesting LBP features\")\n",
    "            exit(1)\n",
    "        all_train = []\n",
    "        image_to_lbps = {}\n",
    "        for key in imgs:\n",
    "\n",
    "            if key in error_faces:\n",
    "                continue\n",
    "\n",
    "            img_patches = create_patch(patch_size, imgs[key], kps[key])\n",
    "            t_lbp = extract_lbps(img_patches, radius)\n",
    "            image_to_lbps[key] = t_lbp\n",
    "            all_train.extend(t_lbp)\n",
    "        return all_train, image_to_lbps\n",
    "\n",
    "\n",
    "def cluster_training_data(train_hogs, name_hogs, n_restarts, vocab_size):\n",
    "    n_comps = vocab_size\n",
    "    images_to_bow = {}\n",
    "    gmm = GaussianMixture(n_components=n_comps, n_init=n_restarts, reg_covar=1e-5, covariance_type='spherical', max_iter=200)\n",
    "    gmm.fit(train_hogs)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for key in name_hogs:\n",
    "        pred = gmm.predict(name_hogs[key])\n",
    "        bag = [0] * n_comps\n",
    "        for i in pred:\n",
    "            bag[i] = bag[i] + 1\n",
    "            \n",
    "        sum_bag = np.sum(bag)\n",
    "\n",
    "        bag = np.array(bag) / sum_bag\n",
    "        images_to_bow[key] = bag\n",
    "        \n",
    "#         if counter < 3:\n",
    "#             plt.bar([i for i in range(n_comps)], bag)\n",
    "#             plt.show()\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "    return images_to_bow, gmm\n",
    "   \n",
    "def find_closest_point(point, points):\n",
    "    closest_label = \"\"\n",
    "    closest_val = sys.maxsize\n",
    "    for p in points:\n",
    "        dist = np.linalg.norm(point - points[p])\n",
    "        if dist < closest_val:\n",
    "            closest_val = dist\n",
    "            closest_label = p\n",
    "            \n",
    "    return closest_label\n",
    "            \n",
    "    # preds = gmm.predict(train_hogs)\n",
    "    # print(np.array(preds).shape)\n",
    "#     preds = gmm.predict(test_hogs)\n",
    "#     print(\"Accuracy: {}\".format(accuracy_score(test_labels, preds)))\n",
    "    # cf = confusion_matrix(list(test_labels.values()), preds)\n",
    "    # plt.imshow(cf)\n",
    "    # plt.show()\n",
    " \n",
    "error_faces = []\n",
    "    \n",
    "face_coords = {\n",
    "    \"train43.jpg\": (100, 80, 30, 30),\n",
    "    \"train31.jpg\": (105, 85, 30, 30),\n",
    "    \"train36.jpg\": (105 ,70, 50, 50),\n",
    "    \"train29.jpg\": (105, 100, 30, 30),\n",
    "    \"train56.jpg\": (110, 65, 30, 30),\n",
    "    \"train21.jpg\": (110, 65, 40, 40),\n",
    "    \"train72.jpg\": (105, 90, 35, 35),\n",
    "    \"train45.jpg\": (100, 90, 35, 35),\n",
    "    \"train9.jpg\": (100, 50, 60, 60)\n",
    "}\n",
    "\n",
    "test_face_coords = {\n",
    "    \"test0.jpg\": (90,50,60,60),\n",
    "    \"test1.jpg\": (105,50,50,50),\n",
    "    \"test2.jpg\": (90,55,50,50),\n",
    "    \"test3.jpg\":(85,65,40,40),\n",
    "    \"test4.jpg\": (78,65,45,45),\n",
    "    \"test5.jpg\": (105,65,45,45),\n",
    "    \"test6.jpg\": (110,65,60,60),\n",
    "    \"test7.jpg\": (110,85,50,50),\n",
    "    \"test8.jpg\": (110,70,50,50),\n",
    "    \"test9.jpg\": (110,70,40,40),\n",
    "    \"test10.jpg\": (90,40,60,60),\n",
    "    \"test11.jpg\": (110,80,45,45),\n",
    "    \"test12.jpg\": (100,50,60,60),\n",
    "    \"test13.jpg\": (90,50,50,50),\n",
    "    \"test14.jpg\": (80,70,50,50),\n",
    "    \"test16.jpg\": (90,50,70,70),\n",
    "    \"test21.jpg\": (110,30,70,70),\n",
    "    \"test24.jpg\": (90,80,40,40),\n",
    "    \"test30.jpg\": (110,45,40,40),\n",
    "    \"test31.jpg\": (100,60,50,50),\n",
    "    \"test33.jpg\": (80,80,50,50),\n",
    "    \"test38.jpg\": (80,80,40,40),\n",
    "    \"test39.jpg\": (110,60,60,60),\n",
    "    \"test41.jpg\": (90,50,50,50),\n",
    "    \"test44.jpg\": (120,50,40,40),\n",
    "    \"test46.jpg\": (110,40,70,70),\n",
    "    \"test47.jpg\": (80,40,60,60),\n",
    "    \"test50.jpg\": (100,50,60,60),\n",
    "    \"test52.jpg\": (100,100,40,40),\n",
    "    \"test55.jpg\": (100,50,50,50),\n",
    "    \"test56.jpg\": (90,50,50,50),\n",
    "    \"test57.jpg\": (110,60,50,50),\n",
    "    \"test58.jpg\": (80,70,50,50),\n",
    "    \"test59.jpg\": (120,40,60,60),\n",
    "    \"test62.jpg\": (100,60,50,50),\n",
    "    \"test65.jpg\": (100,50,45,45),\n",
    "    \"test67.jpg\": (120,80,45,45)\n",
    "}\n",
    "\n",
    "def grid_search(vocab_sizes, patch_sizes, n_restarts, lbp_radii):\n",
    "    best_hog_v = None\n",
    "    best_cell_size = None\n",
    "    best_hog_patch_size = None\n",
    "    best_hog_accuracy = 0\n",
    "    best_lbp_accuracy = 0\n",
    "    best_radius = None\n",
    "    best_lbp_v = None\n",
    "    best_lbp_patch_size = None\n",
    "    hog_confusion_matrix = None\n",
    "    lbp_confusion_matrix = None\n",
    "    count = 0\n",
    "    for v in vocab_sizes:\n",
    "        count += 1\n",
    "        print(\"Iteration {} out of {}\".format(count, len(vocab_sizes)))\n",
    "\n",
    "        for patch_size in patch_sizes:\n",
    "            for new_cell_size in [(3, 3),(4,4),(5,5)]:\n",
    "                # HOGS\n",
    "                all_train, named_hogs =  get_data_and_labels(train_images, keypoints, c_size=new_cell_size, patch_size=patch_size)\n",
    "                all_test, named_hogs_test = get_data_and_labels(test_images,test_keypoints, new_cell_size, patch_size)\n",
    "                train_hists, classifier = cluster_training_data(all_train, named_hogs, n_restarts, v)\n",
    "\n",
    "\n",
    "                true = []\n",
    "                predicted = []\n",
    "                for key in named_hogs_test:\n",
    "                    pred = classifier.predict(named_hogs_test[key])\n",
    "                    bag = [0] * v\n",
    "                    for i in pred:\n",
    "                        bag[i] = bag[i] + 1\n",
    "\n",
    "                    sum_bag = np.sum(bag)\n",
    "                    bag = np.array(bag) / sum_bag\n",
    "                    l = find_closest_point(bag, train_hists)\n",
    "                    true.append(test_labels[key])\n",
    "                    predicted.append(labels[l])\n",
    "                acc = accuracy_score(true, predicted)\n",
    "#                 print(v, new_cell_size, patch_size, acc)\n",
    "                if acc > best_hog_accuracy:\n",
    "                    best_hog_accuracy = acc\n",
    "                    best_hog_v = v\n",
    "                    best_cell_size = new_cell_size\n",
    "                    best_hog_patch_size = patch_size\n",
    "                    hog_confusion_matrix = confusion_matrix(true, predicted)\n",
    "            print(\"Current best  HOG accuracy is {} with vocab_size={} and cell_size={} and patch_size={}\".format(best_hog_accuracy, best_hog_v, best_cell_size, best_hog_patch_size))\n",
    "            # LBP\n",
    "            for radius in lbp_radii:\n",
    "                all_train, named_lbps =  get_data_and_labels(train_images, keypoints, descriptor='lbp', radius=radius, patch_size=patch_size)\n",
    "                all_test, named_lbps_test = get_data_and_labels(test_images,test_keypoints, descriptor='lbp', radius=radius, patch_size=patch_size)\n",
    "\n",
    "                train_hists, classifier = cluster_training_data(all_train, named_lbps, n_restarts, v)\n",
    "\n",
    "\n",
    "                true = []\n",
    "                predicted = []\n",
    "                for key in named_lbps_test:\n",
    "                    pred = classifier.predict(named_lbps_test[key])\n",
    "                    bag = [0] * v\n",
    "                    for i in pred:\n",
    "                        bag[i] = bag[i] + 1\n",
    "\n",
    "                    sum_bag = np.sum(bag)\n",
    "                    bag = np.array(bag) / sum_bag\n",
    "                    l = find_closest_point(bag, train_hists)\n",
    "                    true.append(test_labels[key])\n",
    "                    predicted.append(labels[l])\n",
    "                acc = accuracy_score(true, predicted)\n",
    "                if acc > best_lbp_accuracy:\n",
    "                    best_lbp_accuracy = acc\n",
    "                    best_lbp_v = v\n",
    "                    best_radius = radius\n",
    "                    best_lbp_patch_size = patch_size\n",
    "                    print(true[0], predicted[0])\n",
    "                    lbp_confusion_matrix = confusion_matrix(true, predicted)\n",
    "            print(\"Current best  LBP accuracy is {} with vocab_size={} and radius={} and patch_size={}\".format(best_lbp_accuracy, best_lbp_v, best_radius, best_lbp_patch_size))\n",
    "\n",
    "    print(\"Best HOG accuracy is {} with vocab_size={} and cell_size={} and patch_size={}\".format(best_hog_accuracy, best_hog_v, best_cell_size, best_hog_patch_size))\n",
    "    plt.imshow(hog_confusion_matrix)\n",
    "    plt.show()\n",
    "    print(\"Best LBP accuracy is {} with vocab_size={} and radius={} and patch_size={}\".format(best_lbp_accuracy, best_lbp_v, best_radius, best_lbp_patch_size))\n",
    "    plt.imshow(lbp_confusion_matrix)\n",
    "    plt.show()\n",
    "keypoints = bound_faces(face_coords, train_images, method='sift')\n",
    "\n",
    "with open(\"pictures/train/labels.json\") as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "\n",
    "test_keypoints = bound_faces(test_face_coords, test_images, method='sift')\n",
    "\n",
    "with open(\"pictures/test/labels.json\") as f:\n",
    "    test_labels = json.load(f)\n",
    "\n",
    "test_vocabs = [x for x in range(10, 310, 10)]\n",
    "n_restarts = 3\n",
    "patch_sizes = [15]\n",
    "lbp_radii = [2, 7, 12]\n",
    "grid_search(test_vocabs, patch_sizes, n_restarts, lbp_radii)\n",
    "\n",
    "# Harris\n",
    "# Best HOG accuracy is 0.4927536231884058 with vocab_size=41 and cell_size=(4, 4) and patch_size=17\n",
    "# Best LBP accuracy is 0.5362318840579711 with vocab_size=71 and radius=7 and patch_size=13\n",
    "\n",
    "# SIFT\n",
    "# Best HOG accuracy is 0.5217391304347826 with vocab_size=100 and cell_size=(4, 4) and patch_size=15\n",
    "# Best LBP accuracy is 0.4492753623188406 with vocab_size=120 and radius=2 and patch_size=15\n",
    "\n",
    "# SIFT Patches= 10, 15, 25\n",
    "# Best HOG accuracy is 0.4782608695652174 with vocab_size=100 and cell_size=(4, 4) and patch_size=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}